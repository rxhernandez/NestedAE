 --> User provided command line run_dir argument : ../runs/perovskite_multiscale_dataset_3
 --> User provided command line ae argument : 2
 --> Setting global random seed 0.
 --> Running on cpu.
 --> Number of threads : 10
 --> Number of interop threads : 10
 --> PyTorch configurations


 --> Submodule encoder layers :
ModuleList(
  (0): Linear(in_features=23, out_features=2, bias=True)
  (1): Tanh()
)


 --> Submodule PCE_pred layers :
ModuleList(
  (0): Linear(in_features=2, out_features=100, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.1, inplace=False)
  (3): Linear(in_features=100, out_features=1, bias=True)
  (4): ReLU()
)


 --> Submodule latents_pred layers :
ModuleList(
  (0): Linear(in_features=2, out_features=12, bias=True)
)


 --> Submodule etm_pred layers :
ModuleList(
  (0): Linear(in_features=2, out_features=7, bias=True)
)


 --> Submodule htm_pred layers :
ModuleList(
  (0): Linear(in_features=2, out_features=4, bias=True)
)
 --> Model Compilation step complete.
┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name       ┃ Type       ┃ Params ┃
┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ submodules │ ModuleDict │    518 │
└───┴────────────┴────────────┴────────┘
Trainable params: 518                                                                                               
Non-trainable params: 0                                                                                             
Total params: 518                                                                                                   
Total estimated model params size (MB): 0                                                                           
 --> Example Input : 
{'all_props': tensor([-0.8142, -0.6422, -0.2542,  0.6639,  0.2186,  0.1587,  0.2467, -0.2491,
         0.0837,  0.2491,  0.5617,  0.5617, -0.5617, -0.5617, -0.5617]), 'etm': tensor([0., 0., 0., 0., 0., 1., 0.]), 'htm': tensor([0., 0., 0., 1.]), 'PCE': tensor([13.3000]), 'latents': tensor([ 0.2465,  0.1169, -0.2667, -0.7482, -0.6848,  0.8180, -0.2374, -0.8382,
        -0.6042,  0.6723, -0.2217,  0.6170]), 'pred_bg': tensor([-0.2310])}


--> Model Trace : 


 ---------------------------------- 
module_name:encoder
input id:['latents', 'etm', 'htm']
input to submodule :
tensor([ 0.2465,  0.1169, -0.2667, -0.7482, -0.6848,  0.8180, -0.2374, -0.8382,
        -0.6042,  0.6723, -0.2217,  0.6170,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000])
output id:encoder
output from submodule :
tensor([0.6168, 0.2454], grad_fn=<TanhBackward0>)
Submodule output dictionary :
{'encoder': tensor([0.6168, 0.2454], grad_fn=<TanhBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:PCE_pred
input id:['encoder']
input to submodule :
tensor([0.6168, 0.2454], grad_fn=<CatBackward0>)
output id:PCE_pred
output from submodule :
tensor([0.], grad_fn=<ReluBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([0.6168, 0.2454], grad_fn=<TanhBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:latents_pred
input id:['encoder']
input to submodule :
tensor([0.6168, 0.2454], grad_fn=<CatBackward0>)
output id:latents_pred
output from submodule :
tensor([ 0.1354,  0.0735,  0.4673,  0.2021, -0.3583, -0.1389,  0.0093,  0.0810,
        -0.4834, -0.1884, -0.1465, -0.0252], grad_fn=<AddBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([0.6168, 0.2454], grad_fn=<TanhBackward0>),
 'latents_pred': tensor([ 0.1354,  0.0735,  0.4673,  0.2021, -0.3583, -0.1389,  0.0093,  0.0810,
        -0.4834, -0.1884, -0.1465, -0.0252], grad_fn=<AddBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:etm_pred
input id:['encoder']
input to submodule :
tensor([0.6168, 0.2454], grad_fn=<CatBackward0>)
output id:etm_pred
output from submodule :
tensor([ 0.1611, -0.1436, -0.4037, -0.1517, -0.2763,  0.3917,  0.0474],
       grad_fn=<AddBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([0.6168, 0.2454], grad_fn=<TanhBackward0>),
 'etm_pred': tensor([ 0.1611, -0.1436, -0.4037, -0.1517, -0.2763,  0.3917,  0.0474],
       grad_fn=<AddBackward0>),
 'latents_pred': tensor([ 0.1354,  0.0735,  0.4673,  0.2021, -0.3583, -0.1389,  0.0093,  0.0810,
        -0.4834, -0.1884, -0.1465, -0.0252], grad_fn=<AddBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:htm_pred
input id:['encoder']
input to submodule :
tensor([0.6168, 0.2454], grad_fn=<CatBackward0>)
output id:htm_pred
output from submodule :
tensor([ 0.1423, -1.1607, -0.2903, -0.2241], grad_fn=<AddBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([0.6168, 0.2454], grad_fn=<TanhBackward0>),
 'etm_pred': tensor([ 0.1611, -0.1436, -0.4037, -0.1517, -0.2763,  0.3917,  0.0474],
       grad_fn=<AddBackward0>),
 'htm_pred': tensor([ 0.1423, -1.1607, -0.2903, -0.2241], grad_fn=<AddBackward0>),
 'latents_pred': tensor([ 0.1354,  0.0735,  0.4673,  0.2021, -0.3583, -0.1389,  0.0093,  0.0810,
        -0.4834, -0.1884, -0.1465, -0.0252], grad_fn=<AddBackward0>)}
 ---------------------------------- 


