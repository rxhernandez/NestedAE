 --> User provided command line run_dir argument : ../runs/test_nt
 --> User provided command line ae argument : 1
 --> Setting global random seed 0.
 --> Running on cpu.
 --> Number of threads : 10
 --> Number of interop threads : 10
 --> PyTorch configurations


 --> Submodule encoder layers :
ModuleList(
  (0): Linear(in_features=15, out_features=12, bias=True)
  (1): Tanh()
)


 --> Submodule bg_pred layers :
ModuleList(
  (0): Linear(in_features=12, out_features=100, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.1, inplace=False)
  (3): Linear(in_features=100, out_features=1, bias=True)
  (4): ReLU()
)


 --> Submodule decoder layers :
ModuleList(
  (0): Linear(in_features=12, out_features=15, bias=True)
)
 --> Model Compilation step complete.
┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name       ┃ Type       ┃ Params ┃
┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ submodules │ ModuleDict │  1.8 K │
└───┴────────────┴────────────┴────────┘
Trainable params: 1.8 K                                                         
Non-trainable params: 0                                                         
Total params: 1.8 K                                                             
Total estimated model params size (MB): 0                                       
 --> Example Input : 
{'all_props': tensor([ 0.7606, -0.9868, -1.3115,  1.4568,  1.3006, -1.7735, -0.8108,  1.0684,
         1.4503,  0.8850, -1.2365, -1.3342,  1.2963,  1.3063,  1.2523]), 'bg': tensor([1.9500])}


--> Model Trace : 


 ---------------------------------- 
module_name:encoder
input id:['all_props']
input to submodule :
tensor([ 0.7606, -0.9868, -1.3115,  1.4568,  1.3006, -1.7735, -0.8108,  1.0684,
         1.4503,  0.8850, -1.2365, -1.3342,  1.2963,  1.3063,  1.2523])
output id:encoder
output from submodule :
tensor([-0.7055,  0.2767,  0.2803,  0.5424,  0.3576,  0.9369,  0.8077, -0.9214,
         0.7026, -0.5035, -0.8490, -0.6035], grad_fn=<TanhBackward0>)
Submodule output dictionary :
{'encoder': tensor([-0.7055,  0.2767,  0.2803,  0.5424,  0.3576,  0.9369,  0.8077, -0.9214,
         0.7026, -0.5035, -0.8490, -0.6035], grad_fn=<TanhBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:bg_pred
input id:['encoder']
input to submodule :
tensor([-0.7055,  0.2767,  0.2803,  0.5424,  0.3576,  0.9369,  0.8077, -0.9214,
         0.7026, -0.5035, -0.8490, -0.6035], grad_fn=<CatBackward0>)
output id:bg_pred
output from submodule :
tensor([0.6288], grad_fn=<ReluBackward0>)
Submodule output dictionary :
{'bg_pred': tensor([0.6288], grad_fn=<ReluBackward0>),
 'encoder': tensor([-0.7055,  0.2767,  0.2803,  0.5424,  0.3576,  0.9369,  0.8077, -0.9214,
         0.7026, -0.5035, -0.8490, -0.6035], grad_fn=<TanhBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:decoder
input id:['encoder']
input to submodule :
tensor([-0.7055,  0.2767,  0.2803,  0.5424,  0.3576,  0.9369,  0.8077, -0.9214,
         0.7026, -0.5035, -0.8490, -0.6035], grad_fn=<CatBackward0>)
output id:decoder
output from submodule :
tensor([-0.0679, -0.1412,  0.5127, -0.1462,  0.4777,  0.1627,  0.1290, -0.0851,
         0.5993, -0.3223, -0.1384, -0.2605,  0.4962,  0.9203,  0.6260],
       grad_fn=<AddBackward0>)
Submodule output dictionary :
{'bg_pred': tensor([0.6288], grad_fn=<ReluBackward0>),
 'decoder': tensor([-0.0679, -0.1412,  0.5127, -0.1462,  0.4777,  0.1627,  0.1290, -0.0851,
         0.5993, -0.3223, -0.1384, -0.2605,  0.4962,  0.9203,  0.6260],
       grad_fn=<AddBackward0>),
 'encoder': tensor([-0.7055,  0.2767,  0.2803,  0.5424,  0.3576,  0.9369,  0.8077, -0.9214,
         0.7026, -0.5035, -0.8490, -0.6035], grad_fn=<TanhBackward0>)}
 ---------------------------------- 


